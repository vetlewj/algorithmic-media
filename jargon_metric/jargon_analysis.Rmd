---
output:
pdf_document: default
html_document: default
---

```{r, include=FALSE}
library(data.table)
library(ggplot2)
library(here)
library(dplyr)
library(progress)
library(stargazer)
library(stringr)
library(broom)
```

```{r}
data <- fread(here("data", "combined_for_analysis_sensationalism_jargon_categories_domain_labels.csv"))
# rename Engineering & Tech to Engineering and Tech
data[, top_category := gsub("Engineering & Tech", "Engineering and Tech", top_category)]
colnames(data)
```

```{r}
model_jargon_only = lm(score ~ jargon_proportion, data = data)
model_year = lm(score ~ jargon_proportion + factor(year), data = data)
model_year_month = lm(score ~ jargon_proportion + factor(year) + factor(month), data = data)
model_year_month_top_cat = lm(score ~ jargon_proportion +
  factor(year) +
  factor(month) +
  factor(top_category), data = data)
stargazer(model_jargon_only, model_year, model_year_month, model_year_month_top_cat,
          type = "text",
          omit = "factor",
          column.labels = c("Jargon only", "Jargon, Year",
                            "Jargon, Year and Month", "Jargon, Year, Month, Category")
)
```

-\> We can explain a bit more, when including factors for year months etc. Let's have a look whether that is significantly different:

```{r}
anova(model_jargon_only, model_year)
anova(model_year, model_year_month)
anova(model_year_month, model_year_month_top_cat)
```

*-\> Seems like every single step: Adding year, month and top_category adds power to the model. :::*

Let's look how the months influence our score?

```{r}
stargazer(model_year, model_year_month,
                     type = "text",
                     omit = "year"
)
```

-\> For plotting this look at python analysis file ::: I feel like posts from December are just the best adding about an extra 250 points to the score. ::: Let's see how the year interacts with the jargon on the score:

```{r}
# Interaction terms in years and jargon
model_interaction_jargon_year = lm(score ~ jargon_proportion:factor(year) +
  factor(year) +
  factor(month) - 1, data = data)
anova(model_interaction_jargon_year, model_year_month)

stargazer(model_interaction_jargon_year,
          type = "text",
          omit = 1:18
)

```

Okay seems like that works. Let's look at the interaction terms. I interpret this as how effective the jargon is in the different years.

But: Look at anova: Adding those interactions doesn't really make a difference, we should ignore it.

*Adding interactions between year and jargon doesn't really make a difference, we should ignore it.*

We could do something similar for the month, but I am not sure if it is worth it. Let's do it for the **categories**.

```{r}
model_interaction_jargon_top_category = lm(log(score + 0.00001) ~
                                             jargon_proportion:factor(top_category)
                                               +
                                               factor(year)
                                               +
                                               factor(month)
                                               +
                                               factor(top_category),
                                           data = data
)
model_top_categories_no_interaction = lm(log(score + 0.00001) ~
                                           jargon_proportion
                                             +
                                             factor(year)
                                             +
                                             factor(month)
                                             +
                                             factor(top_category),
                                         data = data
)
anova(model_interaction_jargon_top_category, model_top_categories_no_interaction)
stargazer(model_interaction_jargon_top_category, model_top_categories_no_interaction, type = "text", omit = c("year", "month"),
          covariate.labels = c("Jargon Proportion",
                               "Environmental Sciences", "Life Sciences", "Physical Sciences", "Social Sciences",
                               "Jargon x Engineering and Tech", "Jargon x Environmental Sciences", "Jargon x Life Sciences", "Jargon x Physical Sciences", "Jargon x Social Sciences")
)
```

```{r}
model_interaction_link_flair = data[, lm(log(score + 1) ~ jargon_proportion:factor(link_flair_text) +
  factor(year) +
  factor(month) +
  factor(top_category))]
stargazer(model_interaction_link_flair, type = "text", omit = 1:17)
```

* Interaction terms between jargon and the top categories do seem to be interpretable and significant but not that more explanatory*

-\> Go with top_category only, as it is more interpretable and readable and adjusted r2 is similar

## Trying to make it more interpretable

```{r}
data[, jargon_percentage_times_100 := (jargon_proportion) * 100]
model_log = lm(log(score + 1) ~ jargon_proportion:factor(top_category) +
  factor(year) +
  factor(month) +
  factor(top_category), data = data)
model_log_100_times = lm(log(score + 1) ~ jargon_percentage_times_100:factor(top_category) +
  factor(year) +
  factor(month) +
  factor(top_category), data = data)
model_log_log = lm(log(score + 1) ~ log(jargon_proportion + 0.00001):factor(top_category) +
  factor(year) +
  factor(month) +
  factor(top_category), data = data)


stargazer(model_log, model_log_100_times, model_log_log, type = "text", omit = 1:17) 
```

```{r}
# Beautiful
stargazer(model_log_100_times, model_log_log, type = "text", omit = 1:17, column.labels = c("Jargon x 100", "Log Jargon"),
          covariate.labels = c("Evnironmental Sciences", "Life Sciences", "Physical Sciences", "Social Sciences",
                               "Jargon x 100 x Engineering and Tech", "Jargon x 100 x Environmental Sciences", "Jargon x 100 x Life Sciences", "Jargon x 100 x Physical Sciences", "Jargon x 100 x Social Sciences",
                               "Log Jargon x Engineering and Tech", "Log Jargon x Environmental Sciences", "Log Jargon x Life Sciences", "Log Jargon x Physical Sciences", "Log Jargon x Social Sciences"))
```

Exemplary interpretation: Social Sciences - A 1% increase in jargon_proportion results in an approximate 0.231% increase in score.

```{r}
stargazer(model_interaction_jargon_top_category_new, model_log_100_times, model_log_log, type = "text", omit = 1:17)

```

